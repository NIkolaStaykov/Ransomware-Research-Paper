\documentclass[11pt, a4paper]{article}
\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[bulgarian]{babel}

%% Sets page size and margins
\usepackage[a4paper,top=3cm,bottom=3cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

%% Useful packages
\usepackage{amsmath, amssymb, amsthm,calc,mathabx}
\usepackage{systeme}
\usepackage{graphicx}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage[colorlinks=true, allcolors=black]{hyperref}
\usepackage{wrapfig,lipsum,booktabs}
\usepackage{enumitem}
\usepackage{float}
\usepackage{fmtcount}
\usepackage{multicol}
\usepackage{breqn}
\usepackage{setspace}
\usepackage{hyperref}
\usepackage{mathtools}
\usepackage {tikz}
\usetikzlibrary {positioning}
\usetikzlibrary{shapes.geometric}
\graphicspath{
	{Graphics/}
	{Graphics/BackupFunction/}
}
\newtheorem{theorem}{Theorem}

\newtheorem{lemma}{Lemma}
\newtheorem{prop}{Property}
\newtheorem*{remark}{Remark}

\theoremstyle{definition}
\newtheorem{definition}{Дефиниция}

\setlength{\columnsep}{1cm}
\setlength{\parindent}{1em}

\newcommand\blfootnote[1]{%
	\begingroup
	\renewcommand\thefootnote{}\footnote{#1}%
	\addtocounter{footnote}{-1}%
	\endgroup
}

\begin{document}
\begin{titlepage}
	\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}
	\centering
	\textsc{\LARGE УС БАН '19}\\[1cm]
	\HRule\\[1 cm]
	{\huge\bfseries Рансъмуер и Гъвкави Стратегии за Архивиране}\\[1 cm]
	\HRule\\
    \vfill
			\Large
			\textit{Автор:}
			 \textsc{Никола Стайков}\\
             \vspace{2cm}
			\Large
			\textit{Ментор:}
            \textsc{Явор Папазов}
    \vfill	
	{\large\today}   
	\vfill
\end{titlepage}

\tableofcontents
\newpage
\begin{abstract}
		Рансъмуер е вид компютърен вирус, който критптира файловете на дадена система и изисква да бъде платен откуп, за да бъдат декриптирани. Създателите на рансъмуер могат да правят малки проучвания преди да започнат основната кампания с цел да определят гореспоменатото разпределение. Първата част на този проект разглежда модел, чрез който да бъдат определени оптималните параметри за едно такова проучване. Главната и най-ефективна защита срещу рансъмуер е правенето на архиви. Те на свой ред обаче могат да представляват съществен разход за големите компании, поради което трябва да бъдат внимателно планирани. Това е взето предвид във втората част на проекта, в която е разгледан модел за архивиране на данни, състоящ се от пълни и инкрементални архиви, и е изчислена очакваната цена за възстановяване на данните. Процесът по възстановяване е пресъздаден и анализиран чрез визуализация на python и Монте Карло симулация.
\end{abstract}

\section{Въведение}
		Този проект е разделен на две основни части, разглеждащи съответно модели за оптимизиране на откуп и оптимизиране на архивиране. Изследвайки обстойно двете противоположни позиции, можем да създадем пълна представа за стратегиите едновременно на атакуващите и жертвите. Обмисляйки начини как всяка от двете страни може да подобри стратегията си ни дава идея как да направим стабилна защитна стратегия чрез архивиране.
\section{Теория}
	В тази част са включени всички дефиниции и концепции, които са нужни за цялостното разбиране на проекта.
		\begin{definition}
			\label{def:normdist}
			\emph{Нормално разпределение}, означено  с $N(\mu, \sigma)$, е вид непрекъснато разпределение, където с $\mu$, $\sigma$ и $\sigma^{2}$ са означени среднoто аритметично, стандартната девиация и вариацията съответно.
		\end{definition}
	
		Графиката на тази функция образува крива, често наричана също камбанна крива. Тя има максимум $(x,f(x))$ в $\left(\mu, \dfrac{1}{\sigma\sqrt{2\pi}}\right)$:
		\begin{center}
			\includegraphics[width=0.6\textwidth]{Normal_clean}
		\end{center}
		
		\begin{definition}
			\label{def:def2}
			Разглеждаме нормално разпределение $N(\mu, \sigma)$. \emph{Стандартната стойност}, или \emph{Z-score}, на дадено $x$ показва колко стандартни девиации е то от дадената средна стойност. Пресмята се по формулата $\dfrac{x-\mu}{\sigma}$.
		\end{definition}
	
		\begin{definition}
			\label{def:prob_dist}
			За дадено разпределение \emph{функцията на разпределение} $F(x)$ показва вероятността стохастична променлива, следваща разпределението, да е по-малка или равна на $x$
			$$F_{X}(x)=\mathbb{P}(x\leq X).$$
		\end{definition}
	
		\begin{definition}
			\label{def:prob_dens}
			\emph{Плътност на разпределение} на непрекъсната стохастична променлива $x$, описва вероятността дадена стохастична променлива $x$ да се окаже в произволен интервал. Формално се дефинира чрез
			\begin{align*}
				&\mathbb{P}(x < X \leq x+\Delta)=F_X(x+\Delta)-F_X(x)\\
				&f_X(x)=\lim_{\Delta \rightarrow 0} \frac{F_X(x+\Delta)-F_X(x)}{\Delta}.		
			\end{align*}
		\end{definition}
	
		\begin{definition}
			\label{def:err}
			\emph{Грешка от първи род} е резултат на интегрирането на нормално разпределение, тя приема z-score като параметър и пресмята интеграла между фиксирана точка и средната стойност за разпределението.
			$$\operatorname{erf}(z)=\dfrac{2}{\sqrt{\pi}}\int_{0}^{z}e^{-t^{2}}dt.$$
		\end{definition}
	
		\begin{definition}
			\label{def:Bernoulli_trial}
			\emph{Опит на Бернули} е стохастичен експеримент с два изхода и фиксирани вероятности за провал и успех:
			\begin{center}
				$P(\text{успех})=p$\\
				$P(\text{провал})=1-p.$
			\end{center}
		\end{definition}
		
		\begin{definition}
			\label{def:Binomial_distribution}
			\emph{Биномно разпределение} е статистическото разпределение на изходите (успех/провал) при провеждането на определен брой опити на Бернули.
			За $n$ опита и вероятност за успех $p$ вероятността точно $k$ от тях да са успешни е:
			$$
			P(\text{успех} = k) = \frac{\binom{n}{k}p^{k}(1-p)^{n-k}}{2^k}
			$$
		\end{definition}
		\newpage

	\section{Оптимизиране на откуп}		
		\subsection{Въведение}
			Рансъмуер се появява за първи път през 1989 под формата на the AIDS Troyan, познат също като PC Cyborg.  The AIDS Trojan е бил доста лесен за преодоляване, тъй като използва симетрична криптография, и скоро са били разработени начини файловете да бъдат декриптирани, но този случай поставя началото на развитието на много от модерните заплахи. С навлизането на Интернет, рансъмуер се завръща с нова сили, а именно с the Archiveus Trojan и GPcode от 2006. Друг повратен момент в историята на рансъмуер е създаването на биткойн, и крипто-валутите като цяло, по много причини, някои от тях бидейки анонимността и автоматичните и невъзвръщаеми транзакции\cite{huang2018tracking}.\par
			В изминалите години е имало опити да бъде направен модел на пазара на malware. В \cite{caulfielddynamic}, авторите са създали теоретичен модел, взимайки предвид броя потребители, които имат архиви, както и други фактори като разпространението на информация и надеждност на рансъмуер.           
			В \cite{cartwright2018pay} е изследван различен подход, който разглежда възможността за допълнително уговаряне на цената като игра между жертвата и престъпниците. Тази разработка се фокусира на теория на игрите и комбинаторика.\par
			Доста усилия са положени и за проследяването на плащания, свързани с рансъмуер в блокчейн, тъй като всички те са публични. В резултат на това има публични данни, свързани с тези плащания, предоставени от \cite{paquet2019ransomware} и в \cite{thomas2015framing} човек може да се запознае с много заключенияв, подкрепени с данни, отнасящи се не само до рансъмуер, но и до целия черен пазар.\par
			Моделът в настоящата разработка е базиран на описания в \cite{caulfielddynamic}, но се фокусира върху оптимизирането на параметри, които не са разгледани в споменатата статия.
		\subsection{Подход}
			Този модел описва разпространението на рансъмуер вирус. Намира оптималната цена на откуп за рансъмуер атака, която използва единствено botnets, без ключовия компонент на разпространяване на всеки компютър в мрежата. Този вариант на атаката е сравнително евтин за осъществяване, но има ниска ефективност. Третираме декриптирането на файловете на даден компютър като услуга, а откупа като нейната цена, съответно. \par
			Разглеждаме разпределението на Желанието за плащане (ЖЗП) на дадена тестова група. Това е максималната сума, която някой би платил за данните си. Поставяйки се в позицията на престъпниците се опитваме да открием разпределението чрез изследването на тестови групи от хора и как те реагират на дадена цена. Тези тестове обаче ни струват ценно време тъй като осведомеността на хората се показва постоянно. Искаме да разберем колко и колко големи тестове трябва да провеждаме, така че да направим модел на разпределението с приемлива грешка и в същото време без да губим твърде много време.\par
			За даден размер на тестовата група, изчисляваме грешката на дадена група от "потребители" от математически описаната функция на кривата на търсенето, която извличаме от разпределението на ЖЗП. Започвайки с малка група, постепенно увеличаваме размера на тестовата група, изчислявайки и грешката чрез метода на най-малките квадрати на всяка стъпка.
		\subsection{Модел}
			Тук математическата страна на модела е разгледана подробно, показвайки как са достигнати резултатите и закюченията. Секцията е разделена на две смислови части, съответстващи на параметрите, които моделът изследва.
			\subsubsection{Размер на тестовата група и грешка}
				Тази секция описва математическия модел, използвам за оптимизиране на грешката. Изведени са заключения относно размера на тестовата група.\par
				Приемаме, че стойността на данните на хората следва нормална дистрибуция и я свързваме със стохастичната променлива $p\sim N(500, 150)$. Вероятностната плътност (ВП) на нормална дистрибуция $N(\mu, \sigma)$ е $$\frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{(x-\mu)^{2}}{2\sigma^{2}}}.$$\par\noindent
				За да изчислим функцията на търсене $f(k)$ от ВП за дадена цена $k$, трябва да изчислим
				$$\int_{k}^{\infty}f(x)\operatorname{d} x.$$
				\begin{figure}[H]
					\begin{minipage}{0.48\textwidth}
						\centering
						\includegraphics[width=\linewidth]{ND_integral}
						\caption{ВП}\label{Fig:Data1}
					\end{minipage}$\longrightarrow$
					\begin{minipage}{0.48\textwidth}
						\centering
						\includegraphics[width=\linewidth]{Sample_point}
						\caption{Цена и търсене}\label{Fig:Data2}
					\end{minipage}
				\end{figure}\par\noindent
				Отбелязаме, че интегралът трябва да бъде изчилсен до безкрайност, но след като $k$ стигне $\mu+3\sigma$, резултатът става пренебрежимо малък. Правейки това за цялата функция на разпределението получаваме кривата на търсенето чрез процента хора, които биха платили. Нека означим кривата на търсенето с $F(x)$:
				$$
				F(x)=
				\begin{cases}
					\dfrac{1}{2}\left (1-\operatorname{erf}\left (\dfrac{z}{\sqrt{2}}\right )\right ) 	\text{ако } x>\mu,\\
					\\
					\dfrac{1}{2}\left (1+\operatorname{erf}\left (\dfrac{z}{\sqrt{2}}\right )\right ) \text{ако } x<\mu.
				\end{cases}
				$$\par
				Искаме да оптимизираме броя хора във всяка тестова група. Математическата функция, която искаме да опишем ни дава възможността да изчислим грешките от експерименталните данни с максимална точност.
				\begin{figure}[H]
					\begin{minipage}{0.48\textwidth}
						\centering
						\includegraphics[width=\linewidth]{Exp_and_math_100}
						\caption{100 човека в групата}\label{Fig:Data3}
					\end{minipage}\hfill
					\begin{minipage}{0.48\textwidth}
						\centering
						\includegraphics[width=\linewidth]{Exp_and_math_400}
						\caption{400 човека в групата}\label{Fig:Data4}
					\end{minipage}
				\end{figure}\par\noindent
				Събирайки информация за размера на тестовата груап и грешките, съставяме графика, която показва тези промени.
				\begin{figure}[H]
				\begin{minipage}{1.0\textwidth}
					\centering
					\includegraphics[width=0.7\textwidth]{\dq Error vs sample size 4\dq}
					\caption{Тестов размер и грешка}\label{Fig:Data5}
				\end{minipage}
				\end{figure}
			\subsubsection{Архивираща функция}
				В тази секция описваме функция, отговаряща за вероятността за присъствието на архив. Изчислен е ефектът и върху очакваната печалба.\par
				Първо нека дефинираме архивния итератора $b$: 
				$$
				b=
				\begin{cases}
					1 \text{ ако жертвата има архив},\\
					0 \text{ ако жертвата няма архив}
				\end{cases}
				$$
				Сега нека дефинираме желанието за плащане (ЖЗП):
				$$
				P(x)=
				\begin{cases}
				d_{x} \text{ ако } b_{i}=0,\\
				c \text{ ако } b_{i}=1
				\end{cases}
				$$
				Тук цената на архив е означена с $c$, а цената на данните на жертвата- с $d_{x}$.\par
				Както и по-рано, изчисляваме очакваната вероятност даден човек да плати цена $x$.
				Приемаме, че вероятността конкретна жертва да има архив е константа $p$ и изследваме как промяната на тази стойност влияе на очакваната печалба. Чрез събраните данни създаваме графика, която показва връзката между двете променливи. Измерената грешка е относителна.
				\begin{center}
					\includegraphics[width=0.55\textwidth]{Revenue_vs_backup}
				\end{center}		
		\subsection{Резултати}
			Изследвахме как размерът на тестовата група влияе на грешката на експерименталните данни и също как процента на защитените с архиви влияе на очакваната печалба. Моделът се фокусира на оптимизирането на цената на откупа, но авторът вярва, че за да можем да предприемем подходящи предпазни мерки срещу атаки от този вид, трябва да разбираме всеки ход на престъпниците. Поставяйки се на мястото на извършителите е ключово за целта. Допълнителни резултати, като връзката между очакваната печалба и броя на хората с архиви може да ни помогне да стигнем до подходящи подходи за справяне със заплахата.
	\section{Оптимизиране на архивирането}
		\subsection{Въведение}
			Когато става дума за защита от рансъмуер, най-ефективният метод са архивите. Те на свой ред трябва да бъдат създавани регулярно, защото ефектът от тях при потенциална атака иначе би бил незначителен. Затова е важно протоколите за архивиране да са съставени внимателно и да са съобразени едновременно с рисковете от атака и с нужните за тях ресурси. Нещо повече, оптимизирането на бекъпи може едновременно да увеличи сигурността и да намали разходите.\par
			В тази част на проекта е разгледан модел на архивиране с цел да бъде изчилсена очакваната цена. Подобни модели, разглеждащи пълйни и инкрементални архиви, са създавани и изследвани и преди\cite{nakamura2003optimal}\cite{qian2010optimal}. Разглеждаме цикъл от архиви, който се повтаря между два пълни архива и изследваме как интервалите влияят на очакваната цена на възстановяване и колко бързо ефектът, породен от първоначално незащитените данни преди първия пълен архив, намалява с времето.
		\subsection{Теоретична постановка}
			Настоящият модел е създаден с идеята да изчисли и оптимизира очакваната цена на възстановяване в случай на атака.\par
			Ще разглеждаме ахивът като структура от данни със следните качества:
			$$
			B
			\begin{cases}
			d \text{: the date on which the backup was made, as a day difference from a starting point}\\
			p \text{: the probability that the recovery is unsuccessful for any reason}\\
			r \text{: the price of trying to recover the data from the given backup}
			\end{cases}
			$$
			Два вида архиви са разгледани:
			\begin{enumerate}
				\item Full backup: a backup of the whole database
				\item Incremental backup: only saves the changes from the last backup
			\end{enumerate}
			Атхивите от конкретен вид имат обща вероятност за провал и цена за опит за възстановяване. \par
			За да може един инкрементален архив да е успешен, трябва всички инкрементални архиви преди него до успешен пълен архив също да са успешни, както и самият пълен архив.\par
			В случая цената на данните трябва да се разглежда от субективна гледна точка. Дори и на пазара данните да нямат голяма стойност, ако те са фундаментални за функционирането на компанията, тя ще е готова да плати много за незабавното им възстановяване. Следователно, в описания модел цената на данните се разглежда като вечно увеличаваща се величина и с целите на изследването "скоростта на работа", именно цената на данните, генерирани за един ден, на компанията се счита за константа. Ще я означим с $w$.\par
			Цената на възстановяването на архив ще се разглежда като сума от два фактора:
			\begin{itemize}
				\item Цената на изработването на загубените данни, означена с $W$
				\item Цената на процеса по възстановяването, означена с $R$
			\end{itemize}.
			Дефинираме $W = \Delta t.w$, където с $\Delta t$ означаваме разликата в дни между датана на успешно възстановения архив и датата на атаката, и $R = \sum_{i=1}^{n} r_i$, където броят опити за възстановяване $n$ и 
			$$
			S=\Delta t.w + R,
			$$
			Нека разликата в дни между първият архив и датата на атаката е $T$. В случай, че никой от пълните архиви не се окаже успешен, въвеждаме променлива $W_T$, съответстваща на цената на преработване на цялата работа от начало. Ясно е, че $W_T>T.w$\par
		\subsection{Full backups only}
			Когато разглеждаме само пълни  full backups, the model is simply a Bernoulli distribution with finite trials, namely the number of full backups. We stop when we find a successful backup, starting from the latest and going to the last. Let us define the properties of a full backup($B_F$):
$$
B_F
\begin{cases}
p_F: \text{the probability of failure}\\
r_F: \text{the recovery trial cost}\\
t_F: \text{the days between two consecutive full backups}\\
\end{cases}
$$
Let $k$ be the number of full backups made before the disaster date. Then:
$$
k = \left \lfloor{\frac{T}{t_F}}\right \rfloor + 1
$$
We can now define the expected backup cost:
\begin{equation}
\label{eq:1}
E(T) = p_F^{k}\left(W_T + k.r_F\right) + \displaystyle \sum_{i=0}^{k-1} (1-p_F).p_F^{i}\left( \left (\left\{ \frac{T}{t_F}\right \} + i\right)t_F.w + (i+1).r_F \right )
\end{equation}
This calculation is essential as incremental backups can only work when there is a working full backup and therefore the first thing we need to do is find the latest one. We can now move on to considering the incremental backups given a working full backup.
\subsection{Incremental backups with a working full backup}
We will now consider the case when we have a working backup and we are trying to recover additional data from the incremental backups.\\
\begin{tikzpicture}
[every node/.style={inner sep=0pt}]
\node (1) [circle, minimum size=50.0pt, fill=teal, line width=0.625pt, draw=black] at (50.0pt, -130pt)  {};
\node (2) [circle, minimum size=31.25pt, fill=lime, line width=0.625pt, draw=black] at (135pt, -130pt)  {};
\node (3) [circle, minimum size=31.25pt, fill=lime, line width=0.625pt, draw=black] at (220pt, -130pt)  {};
\node (4) [circle, minimum size=31.25pt, fill=lime, line width=0.625pt, draw=black] at (305pt, -130pt)  {};
\node (5) [circle, minimum size=50.0pt, fill=teal, line width=0.625pt, draw=black] at (390pt, -130pt)  {};
\draw [line width=0.625, ->, >=latex, color=black] (1) to  (2);
\draw [line width=0.625, ->, >=latex, color=black] (2) to  (3);
\draw [line width=0.625, ->, >=latex, color=black] (3) to  (4);
\draw [line width=0.625, ->, >=latex, color=black] (4) to  (5);
\end{tikzpicture}\\
Let	us define the the properties of the incremental backup($B_I$) in a similar fashion:
$$
B_I
\begin{cases}
p_I: \text{the probability of failure}\\
r_I: \text{the recovery trial cost}\\
t_I: \text{the days between two consecutive incremental backups}\\
\end{cases}
$$
\newpage
Let $T_F$ denote the difference in days between the disaster date and the successful full backup and $l$ denote the number of incremental backups we have to consider. We have two options for $l$ depending on whether the latest full backup was successful:
$$
l=
\begin{cases}
\left\lfloor \frac{T_F}{t_I}\right \rfloor \text{, if } T_F<t_F\\
\left\lfloor \frac{t_F}{t_I}\right \rfloor -1 \text{, if } T_F>t_F\footnotemark\\
\end{cases}
$$
\footnotetext{We can only try to recover incremental backups preceding the next full backup}
Note that the last full backup being successful is equivalent to $T_F<t_F$.\par
We are in the exact opposite situation with respect to the previous subsection. The process of recovering incremental backups continues until we conduct an unsuccessful attempt to recover the data, as this will mean none of the following backups can be used either. Note that we are reducing $W$ since in the initial position we are willing to redo the work up to the working full backup. That being said, we are ready to calculate the expected price:
\begin{equation}
\label{eq:2}
f(T_F) = (1-p_I)^l.((T_F-t_I.l).w + r_I.l) + \displaystyle \sum_{i=0}^{l-1} (1-p_I)^{i}.p_I((T_F-t_I.i)w + r_I.(i+1))
\end{equation}
Now we know how much the price will decrease when we use incremental backups and can build the whole picture using equations \ref{eq:1} and \ref{eq:2}.
\subsection{Overall expected price}
For each summand in \ref{eq:1} we should add the effect of incremental backups, so we get new summands of the type:
$$
P(W + R),
$$
where $P$ is the probability of a certain combination of events occurring, $W$ is the cost of the data that has to be reworked and $R$ is the cost of the recovery process. Incremental backups lower the cost of the data that has to be reworked but make $R$ bigger. As mentioned before, there is only one case when the number of incremental backups we have to consider is different and it corresponds to the first full backup being successful. If the $i$-th full backup is successful\footnote{This corresponds to the $i-1$-th summand in the sum from equation \ref{eq:3}}:
$$
T_F=t_F\left(\left\{ \frac{T}{t_F} \right\} + i - 1\right)
$$
By combining equations \ref{eq:1} and \ref{eq:2} we get:
\begin{equation}\label{eq:3}
F(T) = p_F^{k}(W_T+k.r_F) + \displaystyle\sum_{i=0}^{k-1}(1-p_F).p_F^{i}\left(f(T_F) + (i+1).r_F\right)
\end{equation}
Using the described equations \ref{eq:1} and \ref{eq:3}, we can construct a graph of the expected price with and without incremental backups included.
\begin{figure}[H]
	\begin{minipage}{1.0\textwidth}
		\centering
		\includegraphics[width=0.7\textwidth]{Weekly_full.png}
		\caption{Full only and Whole model}\label{Fig:FullWeekly}
	\end{minipage}
\end{figure}
\subsection{Monte Carlo simulation}
A Monte Carlo simulation has been build with python to generate random recovery processes with the described conditions of backup structure. The price of the recovery has been graphed with respect to the disaster date:
\begin{figure}[H]
	\begin{minipage}{1.0\textwidth}
		\centering
		\includegraphics[width=0.7\textwidth]{Weekly_full_carlo.png}
		\caption{Monte Carlo simulation}\label{Fig:MonteCarlo}
	\end{minipage}
\end{figure}
\blfootnote{In both Figure \ref{Fig:FullWeekly} and Figure \ref{Fig:MonteCarlo} the data showed is for a weekly full and daily incremental backups}
The colors in Figure \ref{Fig:MonteCarlo} represent the type of the last backup, which was successful during the recovery, full, incremental or non-existing.
\newpage
A linear regression has been made of the data generated, which is to show that the effect of initial unsecured data fades with time, as the price of failure is calculated as the price to redo the whole work from the creation of the company.
\subsection{Results}
A model for backing up data has been built to calculate the expected price of backup recovery. Furthermore, the effect of incremental backups has been shown, as opposed to a strategy using only full backups. A Monte Carlo simulation has been built and analyzed to demonstrate the real process of recovery.
\section{Further development}
The author considers several future development directions for the project, namely:
\begin{itemize}
	\item considering non-constant work rate for the backup model
	\item expanding the ransomware model to describe more complex way of distributing the ransomware
	\item using the results and databases of related studies in order to back the project with real data\cite{paquet2019ransomware}
	\item considering a dynamic pricing model for the ransomware model
\end{itemize}
\section{Бъдещо развитие}
	Авторът предвижда бъдещето развитие а проекта в няколко посоки, а именно:
	\begin{itemize}
		\item търсене на връзка между архивите и ЖЗП разпеделението
		\item разширяване на модела с цел да описва по-сложен начин на разпространение между машините в дадена система
		\item използването на разултатите и данните на други подобни разработки с цел подкрепянето на проекта с реални данни\cite{paquet2019ransomware}
		\item разглеждане на динамичен модел за определяне на цената.
	\end{itemize}
\section{Благодарности}
Искам да благодаря на своя ментор, Явор Папазов, и на Константин Делчев за безотказната помощ в избора на темата на проекта и последващото му развитие, за снабдяването ми с всички нужни материали за запознаването ми с темата, както и за изслушването на въпросите ми. Искам също да благодаря на Станислав Харизанов за професионалните съвети.
\nocite{*}
\bibliographystyle{unsrt}
\bibliography{Bibliography}
\end{document}